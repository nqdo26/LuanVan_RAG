from fastapi import FastAPI, Request, HTTPException
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import requests
from pinecone import Pinecone, ServerlessSpec
from groq import Groq
from langchain.text_splitter import RecursiveCharacterTextSplitter
import re
import unicodedata
import os
from dotenv import load_dotenv

from models import IngestPayload, QuestionPayload, DeletePayload, ChatCompletionPayload, UpdatePayload

# Load environment variables
load_dotenv()
app = FastAPI()

# ThÃªm exception handler cho validation errors
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    print(f"[VALIDATION ERROR] {exc.errors()}")
    print(f"[REQUEST BODY] {await request.body()}")
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": str(await request.body())}
    )

# Pinecone init
pc = Pinecone(
    api_key=os.getenv("PINECONE_API_KEY")
)

index_name = os.getenv("PINECONE_INDEX_NAME")

# Groq init
client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)

# Define the text splitter vá»›i semantic separators cho du lá»‹ch
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,  # TÄƒng size Ä‘á»ƒ giá»¯ nguyÃªn thÃ´ng tin
    chunk_overlap=100,  # TÄƒng overlap Ä‘á»ƒ giá»¯ context
    separators=[
        "\n### ",  # PhÃ¢n chia theo section headers
        "\n## ",   # Headers nhá» hÆ¡n
        "\n- ",    # List items
        ".\n",     # Káº¿t thÃºc cÃ¢u + newline
        ". ",      # Káº¿t thÃºc cÃ¢u
        "\n",      # Newline
        " "        # Space (fallback)
    ]
)

# Check if the index exists, if not create it
if not pc.has_index(index_name):
    pc.create_index_for_model(
        name=index_name,
        cloud="aws",
        region="us-east-1",
        embed={
            "model":"llama-text-embed-v2",
            "field_map":{"text": "text"}
        }
    )

# Connect to the index
index = pc.Index(index_name)


# Define endpoints
@app.get("/")
def hello_world():
    return {"message": "Hello World!"}

@app.head("/v1/keep-alive")
def health_check():
        return {"status": "healthy"}

@app.post("/v1/ingest")
def ingest(payload: IngestPayload):
        
        # Parse JSON data tá»« backend
        import json
        try:
            destination_data = json.loads(payload.info)
        except:
            # Fallback náº¿u váº«n lÃ  string cÅ©
            destination_data = {"description": payload.info}
        
        # Semantic chunking theo loáº¡i destination
        chunks = create_semantic_chunks(payload.name, destination_data, payload.destinationId, payload.slug)

        # Táº¡o records vá»›i metadata Ä‘áº§y Ä‘á»§
        records = [
            {
                "id": f"{payload.destinationId}-{chunk['type']}",
                "text": chunk['content'],
                'destinationId': payload.destinationId,
                'slug': payload.slug,
                'name': payload.name,
                'chunk_type': chunk['type'],
                'chunk_index': i,
                'total_chunks': len(chunks)
            } for i, chunk in enumerate(chunks)
        ]

        # Batch size of 90 (below Pinecone's limit of 96)
        batch_size = 90
    
        # Split records into batches and upsert
        for i in range(0, len(records), batch_size):
            batch = records[i:i + batch_size]
            index.upsert_records(payload.cityId, batch)

        return {"status": "done", "chunks_processed": len(records)}

@app.post("/v1/update")
def update_destination(payload: UpdatePayload):
    try:

        
        # BÆ°á»›c 1: TÃ¬m vÃ  xÃ³a cÃ¡c chunks cÅ© tá»« Táº¤T Cáº¢ namespaces
        # VÃ¬ cÃ³ thá»ƒ cityId Ä‘Ã£ thay Ä‘á»•i, ta cáº§n tÃ¬m trong táº¥t cáº£ namespaces
        deleted_count = 0
        
        # Láº¥y danh sÃ¡ch táº¥t cáº£ namespaces
        try:
            stats = index.describe_index_stats()
            all_namespaces = list(stats.get('namespaces', {}).keys())
            
            # TÃ¬m vÃ  xÃ³a chunks cÅ© trong táº¥t cáº£ namespaces
            for namespace in all_namespaces:
                try:
                    ids_to_delete = list(index.list(prefix=payload.destinationId, namespace=namespace))
                    if ids_to_delete:
                        index.delete(namespace=namespace, ids=ids_to_delete)
                        deleted_count += len(ids_to_delete)
                except Exception as ns_error:
                    continue
                    
        except Exception as stats_error:
            # Fallback: chá»‰ xÃ³a tá»« namespace hiá»‡n táº¡i
            try:
                ids_to_delete = list(index.list(prefix=payload.destinationId, namespace=payload.cityId))
                if ids_to_delete:
                    index.delete(namespace=payload.cityId, ids=ids_to_delete)
                    deleted_count = len(ids_to_delete)
            except Exception as fallback_error:
                pass
        
        # BÆ°á»›c 2: Parse JSON data tá»« backend (giá»‘ng nhÆ° ingest)
        import json
        try:
            destination_data = json.loads(payload.info)
            print(f"[UPDATE] ğŸ“ Äang update Ä‘á»‹a Ä‘iá»ƒm: {payload.name}")
        except Exception as parse_error:
            destination_data = {"description": payload.info}
        
        # BÆ°á»›c 3: Táº¡o semantic chunks má»›i vá»›i 4 chunks
        chunks = create_semantic_chunks(payload.name, destination_data, payload.destinationId, payload.slug)

        # BÆ°á»›c 4: Táº¡o records má»›i vá»›i metadata Ä‘áº§y Ä‘á»§
        records = [
            {
                "id": f"{payload.destinationId}-{chunk['type']}",
                "text": chunk['content'],
                'destinationId': payload.destinationId,
                'slug': payload.slug,
                'name': payload.name,
                'chunk_type': chunk['type'],
                'chunk_index': i,
                'total_chunks': len(chunks)
            } for i, chunk in enumerate(chunks)
        ]

        # BÆ°á»›c 5: Upsert records má»›i vÃ o namespace má»›i (cityId tá»« payload)
        batch_size = 90
        
        for i in range(0, len(records), batch_size):
            batch = records[i:i + batch_size]
            index.upsert_records(payload.cityId, batch)

        print(f"[UPDATE] âœ… UPDATE THÃ€NH CÃ”NG: {payload.name}")
        
        return {
            "status": "updated", 
            "chunks_deleted": deleted_count,
            "chunks_created": len(records),
            "new_namespace": payload.cityId,
            "destination_name": payload.name
        }
        
    except Exception as e:
        print(f"[UPDATE ERROR] âŒ UPDATE THáº¤T Báº I cho {payload.name}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Update failed: {str(e)}")

@app.post("/v1/question")
def question(payload: QuestionPayload):
    # Define the query

    # Search the dense index vá»›i tÄƒng top_k Ä‘á»ƒ bao phá»§ tá»‘t hÆ¡n
    results = index.search(
        namespace=payload.cityId,
        query={
            "top_k": 12,  # TÄƒng lÃªn vÃ¬ má»—i destination cÃ³ 4 chunks
            "inputs": {
                'text': payload.query
            }
        }
    )

    # Print the results vá»›i thÃ´ng tin chunk type
    for hit in results['result']['hits']:
            chunk_type = hit['fields'].get('chunk_type', 'unknown')
            print(f"id: {hit['_id']:<5} | type: {chunk_type:<10} | destinationId: {hit['fields']['destinationId']} | text: {hit['fields']['text'][:50]}")
            

    chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": (
                "### ğŸ“˜ YÃªu cáº§u:\n"
                f"Tráº£ lá»i cÃ¢u há»i sau báº±ng cÃ¡ch dá»±a trÃªn cÃ¡c Ä‘oáº¡n vÄƒn bÃªn dÆ°á»›i. "
                "Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§, hÃ£y tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c cá»§a báº¡n vÃ  ghi rÃµ Ä‘iá»u Ä‘Ã³.\n\n"
                f"**CÃ¢u há»i:** {payload.query}\n\n"
                "### ğŸ“š Äoáº¡n vÄƒn tham kháº£o:\n"
                # + "\n---\n".join([hit['fields']['text'] for hit in results['result']['hits']]) +
                # "\n\n"
                + "\n---\n".join([
                     f"**Äoáº¡n vÄƒn {i+1}:**\n"
                     f"{hit['fields']['text']}\n"
                     for i, hit in enumerate(results['result']['hits'])
                     ]) +
                "### âœï¸ Ghi chÃº khi tráº£ lá»i:\n"
                "- TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i báº±ng [Markdown] Ä‘á»ƒ há»‡ thá»‘ng `react-markdown` cÃ³ thá»ƒ hiá»ƒn thá»‹ tá»‘t.\n"
                "- ThÃªm emoji phÃ¹ há»£p Ä‘á»ƒ lÃ m ná»•i báº­t ná»™i dung chÃ­nh ğŸ§ ğŸ“ŒğŸ’¡.\n"
                "- Náº¿u cÃ¢u tráº£ lá»i khÃ´ng thá»ƒ rÃºt ra tá»« Ä‘oáº¡n vÄƒn, hÃ£y báº¯t Ä‘áº§u báº±ng cÃ¢u: `DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ gá»£i Ã½ cá»§a tÃ´i, Ä‘á»ƒ cÃ³ thá»ƒ nháº­n gá»£i Ã½ chÃ­nh xÃ¡c hÆ¡n tá»« há»‡ thá»‘ng, vui lÃ²ng chá»n Ä‘iá»ƒm Ä‘áº¿n trÆ°á»›c nhÃ©`"
            )
        }
    ],
    model=payload.model or "deepseek-r1-distill-llama-70b",
    )
    response_dict = chat_completion.model_dump()
    response_dict["choices"][0]["message"]["documents"] = [
        {
            "id": hit["_id"],
            "text": hit["fields"]["text"],
            "destinationId": hit["fields"]["destinationId"],
            "score": hit["_score"]
        } for hit in results['result']['hits']
    ]
    return response_dict

@app.post("/v1/delete-document")
def delete_document(payload: DeletePayload):

    ids_to_delete = list(index.list(prefix=payload.destiationId, namespace=payload.cityId))

    if not ids_to_delete:
        raise HTTPException(status_code=404, detail="KhÃ´ng tÃ¬m tháº¥y vectors nÃ o vá»›i documentId nÃ y.")

    # BÆ°á»›c 2: XoÃ¡ vector theo ID
    index.delete(
        namespace=payload.cityId,
        ids=ids_to_delete
    )

    return {"deleted_ids": ids_to_delete}

# HÃ m clean_text Ä‘á»ƒ xá»­ lÃ½ vÄƒn báº£n
def clean_text(text: str) -> str:
    """
    LÃ m sáº¡ch vÃ  chuáº©n hÃ³a vÄƒn báº£n tiáº¿ng Viá»‡t
    """
    # 1. Chuáº©n hÃ³a Unicode (dÃ¹ng NFC Ä‘á»ƒ ghÃ©p dáº¥u)
    text = unicodedata.normalize("NFC", text)

    # 2. Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t (giá»¯ láº¡i tiáº¿ng Viá»‡t vÃ  chá»¯ sá»‘)
    text = re.sub(r"[^\w\sÃ Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©"
                r"Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]", "", text)

    # 3. Loáº¡i bá» khoáº£ng tráº¯ng dÆ° thá»«a
    text = re.sub(r"\s+", " ", text).strip()

    return text

def create_semantic_chunks(name: str, data: dict, destination_id: str, slug: str = None) -> list:
    """
    Táº¡o 4 chunks semantic cho má»—i destination theo strategy má»›i
    """
    chunks = []
    
    # 1. Tá»•ng quan - ThÃ´ng tin tá»•ng quan (báº¯t Ä‘áº§u báº±ng tÃªn Ä‘á»‹a Ä‘iá»ƒm)
    overview_content = f"**{name}**\n\n"
    
    # MÃ´ táº£ chÃ­nh
    if data.get('description'):
        overview_content += f"{data['description']}\n\n"
    
    # Äiá»ƒm ná»•i báº­t
    if data.get('highlight'):
        overview_content += f"**Äiá»ƒm ná»•i báº­t:** {data['highlight']}\n\n"
    
    chunks.append({
        'type': 'tong-quan',
        'content': overview_content.strip()
    })
    
    # 2. Tráº£i nghiá»‡m - Tráº£i nghiá»‡m vÃ  hoáº¡t Ä‘á»™ng (báº¯t Ä‘áº§u báº±ng tÃªn Ä‘á»‹a Ä‘iá»ƒm)
    experience_content = f"**{name}**\n\n"
    
    # Dá»‹ch vá»¥
    if data.get('services'):
        experience_content += f"**Dá»‹ch vá»¥:** {data['services']}\n\n"
    
    # Hoáº¡t Ä‘á»™ng
    if data.get('activities'):
        experience_content += f"**Hoáº¡t Ä‘á»™ng:** {data['activities']}\n\n"
    
    # ThÃ´ng tin há»¯u Ã­ch
    if data.get('usefulInfo'):
        experience_content += f"**ThÃ´ng tin há»¯u Ã­ch:** {data['usefulInfo']}\n\n"
    
    chunks.append({
        'type': 'trai-nghiem',
        'content': experience_content.strip()
    })
    
    # 3. Thá»±c táº¿ - ThÃ´ng tin thá»±c táº¿ (báº¯t Ä‘áº§u báº±ng tÃªn Ä‘á»‹a Ä‘iá»ƒm)
    practical_content = f"**{name}**\n\n"
    
    # Giá» má»Ÿ cá»­a
    if data.get('openHour'):
        practical_content += f"**Giá» má»Ÿ cá»­a:** {data['openHour']}\n\n"
    
    # PhÃ­ tham quan
    if data.get('fee'):
        practical_content += f"**PhÃ­ tham quan:** {data['fee']}\n\n"
    
    # ThÃ´ng tin liÃªn há»‡
    if data.get('contactInfo'):
        practical_content += f"**LiÃªn há»‡:** {data['contactInfo']}\n\n"
    
    chunks.append({
        'type': 'thuc-te',
        'content': practical_content.strip()
    })
    
    # 4. Danh má»¥c - Tags vÃ  tá»« khÃ³a tÃ¬m kiáº¿m (báº¯t Ä‘áº§u báº±ng tÃªn Ä‘á»‹a Ä‘iá»ƒm)
    tags_content = f"**{name}**\n\n"
    
    # Tags chÃ­nh
    if data.get('tags'):
        tags_content += f"**Danh má»¥c:** {data['tags']}\n\n"
    
    # Loáº¡i hÃ¬nh du lá»‹ch - chuyá»ƒn tá»« chunk tá»•ng quan
    if data.get('cultureType'):
        tags_content += f"**Loáº¡i hÃ¬nh:** {data['cultureType']}\n\n"

    chunks.append({
        'type': 'danh-muc',
        'content': tags_content.strip()
    })
    
    return chunks

@app.post("/v1/chat/completions")
def create_chat_completion(payload: ChatCompletionPayload):
    """
    Chat completion cho Gobot - trá»£ lÃ½ du lá»‹ch Viá»‡t Nam
    """
    # ThÃ´ng bÃ¡o chung khi chÆ°a chá»n thÃ nh phá»‘
    notice = (
        "ğŸ‘‹ Xin chÃ o! Hiá»‡n táº¡i báº¡n **chÆ°a chá»n thÃ nh phá»‘** hoáº·c Ä‘iá»ƒm Ä‘áº¿n cá»¥ thá»ƒ.\n"
        "Äá»ƒ nháº­n gá»£i Ã½ **chÃ­nh xÃ¡c tá»« há»‡ thá»‘ng**, hÃ£y chá»n má»™t thÃ nh phá»‘ trÆ°á»›c nhÃ©! ğŸ™ï¸\n"
    )

    # -----------------------
    # 1ï¸âƒ£ KhÃ´ng dÃ¹ng Knowledge
    # -----------------------
    if not payload.isUseKnowledge or not payload.cityId:
        messages_for_api = [msg.model_dump() for msg in payload.messages]
        user_question = messages_for_api[-1]["content"] if messages_for_api else ""

        system_prompt = (
            "Báº¡n lÃ  **Gobot**, trá»£ lÃ½ du lá»‹ch thÃ´ng minh vÃ  thÃ¢n thiá»‡n cá»§a website **GoOhNo**, ná»n táº£ng há»— trá»£ lÃªn káº¿ hoáº¡ch du lá»‹ch Viá»‡t Nam.\n"
            "Báº¡n Ä‘Ã³ng vai trÃ² nhÆ° má»™t **hÆ°á»›ng dáº«n viÃªn báº£n Ä‘á»‹a**, trÃ² chuyá»‡n tá»± nhiÃªn vÃ  gáº§n gÅ©i Ä‘á»ƒ giÃºp ngÆ°á»i dÃ¹ng khÃ¡m phÃ¡ Viá»‡t Nam dá»… dÃ ng.\n"
            "Quy táº¯c quan trá»ng:\n"
            "1. Chá»‰ tÆ° váº¥n vá» cÃ¡c Ä‘á»‹a Ä‘iá»ƒm, hoáº¡t Ä‘á»™ng vÃ  tráº£i nghiá»‡m du lá»‹ch táº¡i Viá»‡t Nam.\n"
            "2. Tráº£ lá»i báº±ng **tiáº¿ng Viá»‡t**, giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n, gáº§n gÅ©i, dá»… hiá»ƒu.\n"
            "3. TrÃ¬nh bÃ y báº±ng **Markdown** vá»›i tiÃªu Ä‘á», danh sÃ¡ch vÃ  emoji minh há»a (ğŸ“ğŸ–ï¸â˜•ğŸœğŸ¯).\n"
            "4. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i: *TÃ´i khÃ´ng cháº¯c vá» Ä‘iá»u nÃ y.*\n"
            "5. Cuá»‘i cÃ¢u tráº£ lá»i, thÃªm **lá»i khuyÃªn há»¯u Ã­ch cho du khÃ¡ch** vÃ  nháº¯c nháº¹ ráº±ng há» cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm trÃªn GoOhNo.\n"
        )


        user_prompt = (
            f"\"CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {user_question}\"\n"
            "\"HÃ£y tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c ná»n vá» du lá»‹ch Viá»‡t Nam.\"\n"
            "\"ÄÆ°a ra cÃ¡c gá»£i Ã½ chi tiáº¿t, dá»… Ä‘á»c, kÃ¨m emoji minh há»a.\"\n"
            "\"Chia nhá» ná»™i dung thÃ nh má»¥c hoáº·c danh sÃ¡ch Markdown.\"\n"
            "\"Káº¿t thÃºc báº±ng lá»i khuyÃªn há»¯u Ã­ch vÃ  thÃ¢n thiá»‡n.\"\n"
        )

        messages = [
            {"role": "system", "content": system_prompt},
            *messages_for_api,
            {"role": "user", "content": user_prompt},
        ]

        fallback_models = [
            payload.model or "llama-3.3-70b-versatile",
            "llama-3.1-70b-versatile",
            "mixtral-8x7b-32768"
        ]

        response_dict = None
        last_error = None

        for attempt, model in enumerate(fallback_models):
            try:
                print(f"[NO-KNOWLEDGE ATTEMPT {attempt+1}] Model: {model}")
                chat_completion = client.chat.completions.create(
                    messages=messages,
                    model=model,
                    temperature=0.4,
                    top_p=0.9,
                    max_completion_tokens=1024,
                )
                response_dict = chat_completion.model_dump()
                print(f"[SUCCESS] Model {model} worked!")
                break
            except Exception as e:
                last_error = e
                if attempt < len(fallback_models) - 1:
                    print(f"[FALLBACK] Error with {model}: {str(e)}")
                    continue

        if response_dict is None:
            raise HTTPException(status_code=500, detail=f"All fallback models failed. Last error: {str(last_error)}")

        # LÃ m sáº¡ch ná»™i dung tráº£ lá»i
        if response_dict.get("choices") and response_dict["choices"][0].get("message"):
            content = response_dict["choices"][0]["message"]["content"]
            import re
            content = re.sub(r'<thinking>.*?</thinking>', '', content, flags=re.DOTALL)
            content = re.sub(r'(Alright|First|I need|The user).*?(?=\n\n|\n[A-ZÃ€-á»¸])', '', content, flags=re.DOTALL)
            content = re.sub(r'\n\s*\n\s*\n', '\n\n', content).strip()
            response_dict["choices"][0]["message"]["content"] = f"{notice}\n{content}"

        return response_dict

    # -----------------------
    # 2ï¸âƒ£ DÃ¹ng Knowledge
    # -----------------------
    messages_for_api = [msg.model_dump() for msg in payload.messages]
    combined_question = clean_text(
        " ".join([msg.content for msg in payload.messages if msg.role == "user"])
    )

    results = index.search(
        namespace=payload.cityId,
        query={"top_k": 12, "inputs": {"text": combined_question}},  # TÄƒng top_k cho 4 chunks má»—i destination
    )
    hits = results.get("result", {}).get("hits", [])

    # Lá»c quÃ¡n cÃ  phÃª
    user_question = payload.messages[-1].content.lower()
    cafe_keywords = ["cÃ  phÃª", "coffee", "quÃ¡n cafe", "quÃ¡n cÃ  phÃª", "cafe 24h"]
    if any(kw in user_question for kw in cafe_keywords):
        filtered_hits = [
            hit for hit in hits
            if "cafe" in (hit["fields"].get("type","") + hit["fields"].get("category","")).lower()
            or "cÃ  phÃª" in (hit["fields"].get("type","") + hit["fields"].get("category","")).lower()
            or "coffee" in (hit["fields"].get("name","")).lower()
            or "cÃ  phÃª" in (hit["fields"].get("name","")).lower()
        ]
        if filtered_hits:
            hits = filtered_hits

    if not hits:
        return {
            "choices": [
                {"message": {"content": f"{notice}\nâš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u phÃ¹ há»£p."}}
            ]
        }

    # -----------------------
    # 3ï¸âƒ£ Chuáº©n bá»‹ prompt
    # -----------------------
    # TrÃ­ch xuáº¥t tÃªn Ä‘á»‹a Ä‘iá»ƒm tá»« hits
    destination_names = []
    reference_texts_with_names = []
    
    for hit in hits:
        dest_name = hit["fields"].get("name", "")
        if dest_name and dest_name not in destination_names:
            destination_names.append(dest_name)
        
        # Äáº£m báº£o text luÃ´n cÃ³ tÃªn Ä‘á»‹a Ä‘iá»ƒm
        text = hit["fields"]["text"]
        if dest_name and dest_name not in text:
            text = f"**{dest_name}**: {text}"
        reference_texts_with_names.append(text)
    
    reference_texts = "\n---\n".join(reference_texts_with_names)

    system_prompt = (
        "Báº¡n lÃ  **Gobot**, trá»£ lÃ½ du lá»‹ch Viá»‡t Nam thÃ¢n thiá»‡n vÃ  hiá»ƒu biáº¿t ğŸ‡»ğŸ‡³.\n"
        "Quy táº¯c:\n"
        "1. Chá»‰ tÆ° váº¥n cÃ¡c Ä‘á»‹a Ä‘iá»ƒm vÃ  tráº£i nghiá»‡m táº¡i Viá»‡t Nam.\n"
        "2. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, giá»ng Ä‘iá»‡u tá»± nhiÃªn, dá»… gáº§n, nhÆ° Ä‘ang trÃ² chuyá»‡n.\n"
        "3. TrÃ¬nh bÃ y báº±ng **Markdown** vá»›i tiÃªu Ä‘á», danh sÃ¡ch vÃ  emoji (ğŸ“â˜•ğŸ–ï¸ğŸœğŸ¯).\n"
        "4. **QUAN TRá»ŒNG**: LuÃ´n sá»­ dá»¥ng TÃŠN CHÃNH XÃC cá»§a Ä‘á»‹a Ä‘iá»ƒm tá»« dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p.\n"
        "5. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i: *TÃ´i khÃ´ng cháº¯c vá» Ä‘iá»u nÃ y.*\n"
        "6. Káº¿t thÃºc cÃ¢u tráº£ lá»i báº±ng **lá»i khuyÃªn há»¯u Ã­ch cho khÃ¡ch du lá»‹ch**.\n"
    )

    user_prompt = (
        f"\"CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {payload.messages[-1].content}\"\n"
        "\"Dá»±a trÃªn cÃ¡c thÃ´ng tin tham kháº£o tá»« há»‡ thá»‘ng, hÃ£y tráº£ lá»i Ä‘áº§y Ä‘á»§ vÃ  thÃ¢n thiá»‡n.\"\n"
        f"\"CÃ¡c Ä‘á»‹a Ä‘iá»ƒm cÃ³ sáºµn: {', '.join(destination_names)}\"\n"
        "\"ThÃ´ng tin chi tiáº¿t:\" \n"
        f"{reference_texts}\n\n"
        "\"QUAN TRá»ŒNG: HÃ£y sá»­ dá»¥ng CHÃNH XÃC tÃªn Ä‘á»‹a Ä‘iá»ƒm tá»« danh sÃ¡ch trÃªn.\"\n"
        "\"TrÃ¬nh bÃ y dÆ°á»›i dáº¡ng danh sÃ¡ch Markdown vá»›i emoji, cÃ³ tÃªn Ä‘á»‹a Ä‘iá»ƒm rÃµ rÃ ng.\"\n"
        "\"Káº¿t thÃºc báº±ng má»™t lá»i khuyÃªn há»¯u Ã­ch vÃ  thÃ¢n thiá»‡n.\"\n"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        *messages_for_api,
        {"role": "user", "content": user_prompt},
    ]

    fallback_models = [
        payload.model or "deepseek-r1-distill-llama-70b",
        "llama-3.3-70b-versatile",
        "llama-3.1-70b-versatile",
        "mixtral-8x7b-32768"
    ]

    response_dict = None
    last_error = None

    for attempt, model in enumerate(fallback_models):
        try:
            print(f"[ATTEMPT {attempt+1}] Model: {model}")
            chat_completion = client.chat.completions.create(
                messages=messages,
                model=model,
                temperature=0.2,
                top_p=0.85,
                max_completion_tokens=800,
            )
            response_dict = chat_completion.model_dump()
            print(f"[SUCCESS] Model {model} worked!")
            break
        except Exception as e:
            last_error = e
            print(f"[ERROR] {model}: {str(e)}")
            if attempt < len(fallback_models) - 1:
                continue

    if response_dict is None:
        raise HTTPException(status_code=500, detail=f"All models failed. Last error: {str(last_error)}")

    # LÃ m sáº¡ch output vÃ  tráº£ vá» kÃ¨m danh sÃ¡ch Ä‘iá»ƒm Ä‘áº¿n
    if response_dict.get("choices") and response_dict["choices"][-1].get("message"):
        content = response_dict["choices"][-1]["message"]["content"]
        import re
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content).strip()
        response_dict["choices"][-1]["message"]["content"] = content

    response_dict["choices"][-1]["message"]["destinations"] = [
        {
            "id": hit.get("_id") or hit.get("id", ""),
            "text": hit["fields"]["text"],
            "destinationId": hit["fields"].get("destinationId"),
            "slug": hit["fields"].get("slug"),
            "name": hit["fields"].get("name"),
            "chunk_type": hit["fields"].get("chunk_type", "unknown"),
            "score": hit.get("_score", 0),
        } for hit in hits
    ]

    return response_dict
